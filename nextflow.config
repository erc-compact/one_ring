
plugins {
    id 'nf-live-tracking@2.0.0'
}

params {

//Observation INFO
project = "COMPACT"
pipeline_name = "Segmented Acceleration Search"
telescope = "MeerKAT"
target = "M28"
files_to_search="${baseDir}/sample_file.txt"
outputdir = "results" //Fill in the beam name here in production
use_kafka = 1

readfile{
    parser = "${baseDir}/readfile_parser.sh"
}

filtool {
    rfi_filter = "kadaneF 8 4 zdot"
    zap_string = ""
    extra_args = "" //(Any additional flags eg -scloffs)
    telescope = "meerkat"
    filplan = ""
    time_decimation_factor = 1
    freq_decimation_factor = 1
    nbits = 8
    mean = 128
    std = 6
    threads = 12
    get_metadata = "${baseDir}/get_metadata.py"

}

// Define a list of configurations as a JSON string, each one corresponding to a peasoup run.
// A user can have one, or many. If only one is desired, provide a single map.
peasoup = '''
    [
      {
        "fft_size": "134217728",
        "start_sample": "0",
        "nsamples": null,
        "acc_start": "-30.0",
        "acc_end": "30.0",
        "dm_pulse_width": "64",
        "acc_pulse_width": "64",
        "min_snr": "8.0",
        "ram_limit_gb": "100.0",
        "nh": "5",
        "ngpus": "1",
        "total_cands": "100000",
        "accel_tol": 1.11,
        "birdie_list": null,
        "chan_mask": null
      },
      {
        "fft_size": "67108864",
        "start_sample": "0",
        "nsamples": null,
        "acc_start": "-100.0",
        "acc_end": "100.0",
        "dm_pulse_width": "64",
        "acc_pulse_width": "64",
        "min_snr": "7.5",
        "ram_limit_gb": "50.0",
        "nh": "5",
        "ngpus": "1",
        "total_cands": "50000",
        "accel_tol": 1.11,
        "birdie_list": null,
        "chan_mask": null
      },
      {
        "fft_size": "67108864",
        "start_sample": "67108864",
        "nsamples": null,
        "acc_start": "-100.0",
        "acc_end": "100.0",
        "dm_pulse_width": "64",
        "acc_pulse_width": "64",
        "min_snr": "7.5",
        "ram_limit_gb": "50.0",
        "nh": "5",
        "ngpus": "1",
        "total_cands": "50000",
        "accel_tol": 1.11,
        "birdie_list": null,
        "chan_mask": null
      }
    ]
    '''
/* 
 * Dispersion Plan Definition (`dd_plan`)
 * 
 * FORMAT:
 * <coherent_dm>:<start_incoherent_dm>:<end_incoherent_dm>:<dm_step>:<tscrunch>
 *
 * Fields:
 * - coherent_dm        : Coherent dispersion measure used during recording.
 * - start_incoherent_dm: Starting DM to perform dedispersion.
 * - end_incoherent_dm  : Ending DM to perform dedispersion.
 * - dm_step            : Step size of DM trials.
 * - tscrunch           : Time-scrunching factor (averaging over time).
 *
 * The pipeline selects rows based on the `coherent_dm` and `subband_dm` values in your filterbank csv file:
 * - If only `coherent_dm` is given, rows with the matching `coherent_dm` will be selected.
 * - If both `coherent_dm` and `subband_dm` are given, `subband_dm` will be used to match rows.
 * - If no values are given, rows starting with `coherent_dm = 0` will run in parallel.
 */

// Example Dispersion Plan
dd_plan = [
    // For observations with coherent DM 0.0, process incoherent DMs from 0.0 to 100.0 with a step size of 1 and tscrunch of 1
    "0.0:0.0:100.0:1:1",
    
    // For observations with coherent DM 120, process incoherent DMs from 110 to 130 with a step size of 0.5 and tscrunch of 1
    "120:110:130:0.5:1",

    "122:112:132:0.5:1"

]


pulsarx{
    fast_nbins = 128
    slow_nbins = 64
    nsubband = 64
    subint_length = null //Default value. Tobs/64
    fold_template = "${baseDir}/meerkat_fold.template"
    clfd_q_value = 2.0
    rfi_filter = "zdot"
    threads = 12

}

prepfold{
    ncpus = 6 //Number of parallel folds
    mask = null
}

rfifind{
    rfifind_time = "2.2"
    rfifind_freqsig = "3.0"
    rfifind_timesig = "10.0"
    rfifind_intfrac = "0.3"
    rfifind_chanfrac = "0.7"
    rfifind_nthreads = "4"
}

folding {
    fold_script = "${baseDir}/fold_peasoup_candidates.py"
}
   
kafka {
server = "localhost:9092"
schema_registry_url = "http://localhost:8081"
schema_file = "${baseDir}/avro_schema/Processing.avsc"
topic = "processing"
message_create= "${baseDir}/create_message.py"
producer_script = "${baseDir}/kafka_producer.py"
save_search_candidate_uuid = "${baseDir}/generate_uuid_search_candidate.py"
merged_fold_search = "${baseDir}/merge_fold_candidates_for_kafka.py"
}

candyjar{
    prepare_candyjar = "${baseDir}/prepare_cands_for_candyjar.py"
}

live {
    enabled = true
    file = "${params.outputdir}/PROGRESS"
    overwrite = true
    interval = 5  // Interval in seconds for JSON dumps

}

weblog {
    enabled = true
    url = 'http://localhost:8000/weblog'
}


}

profiles {
   local {
    includeConfig 'local.config'   
 }
   hercules {
    includeConfig 'hercules.config'
  }
  ozstar {
    includeConfig 'ozstar.config'
  }
  nt {
    includeConfig 'nt.config'
  }
  contra {
    includeConfig 'contra.config'
  }
  }


